{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snowflake-connector-python in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.13.2)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from snowflake-connector-python) (1.17.1)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from snowflake-connector-python) (44.0.0)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=22.0.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from snowflake-connector-python) (24.3.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from snowflake-connector-python) (2.10.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from snowflake-connector-python) (2025.1)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from snowflake-connector-python) (2.32.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\siddh\\appdata\\roaming\\python\\python312\\site-packages (from snowflake-connector-python) (24.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from snowflake-connector-python) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from snowflake-connector-python) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from snowflake-connector-python) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions<5,>=4.3 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from snowflake-connector-python) (4.12.2)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from snowflake-connector-python) (3.17.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in c:\\users\\siddh\\appdata\\roaming\\python\\python312\\site-packages (from snowflake-connector-python) (4.3.6)\n",
      "Requirement already satisfied: tomlkit in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from snowflake-connector-python) (0.13.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0->snowflake-connector-python) (2.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install snowflake-connector-python\n",
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake Warehouse: COMPUTE_WH\n",
      "Snowflake Account: tm52713.ap-south-1\n",
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define connection parameters correctly\n",
    "connection_param = {\n",
    "    \"user\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    \"password\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    \"account\": \"tm52713.ap-south-1\",\n",
    "    \"database\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"schema\": os.getenv(\"SNOWFLAKE_SCHEMA\"),\n",
    "    \"warehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\")\n",
    "}\n",
    "\n",
    "# for testinbg \n",
    "print(f\"Snowflake Warehouse: {connection_param['warehouse']}\")\n",
    "print(f\"Snowflake Account: {connection_param['account']}\")\n",
    "\n",
    "session = snowflake.connector.connect(**connection_param)\n",
    "cursor = session.cursor()\n",
    "print(\"Connection successful\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_file_path = os.path.join(\"sample_data\", \"customers.csv\") \n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to check the data type to set datatype dynamicaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Region</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Customer City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Lauren Barr</td>\n",
       "      <td>North</td>\n",
       "      <td>morganamy@gmail.com</td>\n",
       "      <td>001-508-070-2916x67243</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Johnstonville</td>\n",
       "      <td>UK</td>\n",
       "      <td>77597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mary Beard</td>\n",
       "      <td>South</td>\n",
       "      <td>shannon87@hotmail.com</td>\n",
       "      <td>420-109-5170</td>\n",
       "      <td>Education</td>\n",
       "      <td>Port Shelleyton</td>\n",
       "      <td>Australia</td>\n",
       "      <td>86104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Keith Rodriguez</td>\n",
       "      <td>North</td>\n",
       "      <td>charlesbarnes@reeves.com</td>\n",
       "      <td>001-789-191-8379x677</td>\n",
       "      <td>Hospitality</td>\n",
       "      <td>West Tracyfurt</td>\n",
       "      <td>India</td>\n",
       "      <td>57612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karen Frazier</td>\n",
       "      <td>East</td>\n",
       "      <td>fhernandez@yahoo.com</td>\n",
       "      <td>+1-021-627-2409x9163</td>\n",
       "      <td>Education</td>\n",
       "      <td>Samuelport</td>\n",
       "      <td>France</td>\n",
       "      <td>8929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>James Harrell</td>\n",
       "      <td>South</td>\n",
       "      <td>john44@mcbride.biz</td>\n",
       "      <td>091.780.9802x12362</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Jessicabury</td>\n",
       "      <td>USA</td>\n",
       "      <td>30154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer ID    Customer Name Region                     Email  \\\n",
       "0            1      Lauren Barr  North       morganamy@gmail.com   \n",
       "1            2       Mary Beard  South     shannon87@hotmail.com   \n",
       "2            3  Keith Rodriguez  North  charlesbarnes@reeves.com   \n",
       "3            4    Karen Frazier   East      fhernandez@yahoo.com   \n",
       "4            5    James Harrell  South        john44@mcbride.biz   \n",
       "\n",
       "                    Phone     Industry    Customer City    Country    Zip  \n",
       "0  001-508-070-2916x67243   Healthcare    Johnstonville         UK  77597  \n",
       "1            420-109-5170    Education  Port Shelleyton  Australia  86104  \n",
       "2    001-789-191-8379x677  Hospitality   West Tracyfurt      India  57612  \n",
       "3    +1-021-627-2409x9163    Education       Samuelport     France   8929  \n",
       "4      091.780.9802x12362       Retail      Jessicabury        USA  30154  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_column_type(col, df):\n",
    "    if df[col].dtype == 'int64':\n",
    "        return 'INTEGER'\n",
    "    elif df[col].dtype == 'float64':\n",
    "        return 'FLOAT'\n",
    "    else:\n",
    "        return 'STRING'\n",
    "    \n",
    "# type dynamically\n",
    "columns = df.columns.tolist()\n",
    "column_definitions = \", \".join([f'\"{col}\" {get_column_type(col, df)}' for col in columns])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'customers' already exists in db 'API_DB'.\n"
     ]
    }
   ],
   "source": [
    "schema_name = connection_param[\"schema\"] \n",
    "table_name = \"customers\"\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM {schema_name}.INFORMATION_SCHEMA.TABLES \n",
    "    WHERE TABLE_NAME = '{table_name.upper()}'\n",
    "\"\"\")\n",
    "table_exists = cursor.fetchone()[0] > 0\n",
    "if table_exists:\n",
    "    print(f\"Table '{table_name}' already exists in db '{schema_name}'.\")\n",
    "else:\n",
    "    create_table_query = f'CREATE TABLE {table_name} ({column_definitions})'\n",
    "    cursor.execute(create_table_query)\n",
    "    print(f\"Table '{table_name}' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data intop snowflake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into 'customers' successfully.\n"
     ]
    }
   ],
   "source": [
    "# Construct INSERT query with placeholders\n",
    "columns_str = \", \".join([f'\"{col}\"' for col in columns])\n",
    "placeholders = \", \".join([\"%s\"] * len(columns))\n",
    "insert_query = f'INSERT INTO {table_name} ({columns_str}) VALUES ({placeholders})'\n",
    "\n",
    "# Convert DataFrame to list of tuples\n",
    "data = [tuple(row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "# Execute batch insert safely\n",
    "cursor.executemany(insert_query, data)\n",
    "print(f\"Data inserted into '{table_name}' successfully.\")\n",
    "\n",
    "# Commit and close connection\n",
    "session.commit()\n",
    "cursor.close()\n",
    "session.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# similarly for other csv file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake Warehouse: COMPUTE_WH\n",
      "Snowflake Account: tm52713.ap-south-1\n",
      "Connection successful\n",
      "Schema 'API_SCHEMA' exists.\n",
      "Table 'exchange_rates' already exists in db 'API_SCHEMA'.\n",
      "Data inserted into 'exchange_rates' successfully.\n"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define connection parameters correctly\n",
    "connection_param = {\n",
    "    \"user\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    \"password\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    \"account\": \"tm52713.ap-south-1\",\n",
    "    \"database\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"schema\": os.getenv(\"SNOWFLAKE_SCHEMA\"),\n",
    "    \"warehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\")\n",
    "}\n",
    "\n",
    "# for testinbg \n",
    "print(f\"Snowflake Warehouse: {connection_param['warehouse']}\")\n",
    "print(f\"Snowflake Account: {connection_param['account']}\")\n",
    "\n",
    "session = snowflake.connector.connect(**connection_param)\n",
    "cursor = session.cursor()\n",
    "print(\"Connection successful\")\n",
    "\n",
    "csv_file_path = os.path.join(\"sample_data\", \"exchange_rates.csv\") \n",
    "df = pd.read_csv(csv_file_path)\n",
    "def get_column_type(col, df):\n",
    "    if df[col].dtype == 'int64':\n",
    "        return 'INTEGER'\n",
    "    elif df[col].dtype == 'float64':\n",
    "        return 'FLOAT'\n",
    "    else:\n",
    "        return 'STRING'\n",
    "    \n",
    "# type dynamically\n",
    "columns = df.columns.tolist()\n",
    "column_definitions = \", \".join([f'\"{col}\" {get_column_type(col, df)}' for col in columns])\n",
    "# df.head()\n",
    "# Your error \"Database 'API_SCHEMA' does not exist or not authorized.\" means that Snowflake is treating API_SCHEMA as a database instead of a schema.\n",
    "# This happens because in Snowflake, you must always specify the database first when referencing schemas and tables.\n",
    "database_name = connection_param[\"database\"] \n",
    "schema_name = connection_param[\"schema\"] \n",
    "table_name = \"exchange_rates\"\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM {database_name}.INFORMATION_SCHEMA.SCHEMATA \n",
    "    WHERE SCHEMA_NAME = '{schema_name.upper()}'\n",
    "\"\"\")\n",
    "schema_exists = cursor.fetchone()[0] > 0  \n",
    "\n",
    "if schema_exists:\n",
    "    print(f\"Schema '{schema_name}' exists.\")\n",
    "    cursor.execute(f\"USE SCHEMA {schema_name}\")  \n",
    "else:\n",
    "    raise ValueError(f\"Schema '{schema_name}' does not exist in Snowflake. Please check your connection settings.\")\n",
    "\n",
    "# cursor.execute(f\"USE SCHEMA {schema_name}\")\n",
    "\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM {database_name}.INFORMATION_SCHEMA.TABLES \n",
    "    WHERE TABLE_SCHEMA = '{schema_name.upper()}'\n",
    "    AND TABLE_NAME = '{table_name.upper()}'\n",
    "\"\"\")\n",
    "table_exists = cursor.fetchone()[0] > 0\n",
    "if table_exists:\n",
    "    print(f\"Table '{table_name}' already exists in db '{schema_name}'.\")\n",
    "else:\n",
    "    create_table_query = f'CREATE TABLE {table_name} ({column_definitions})'\n",
    "    cursor.execute(create_table_query)\n",
    "    print(f\"Table '{table_name}' created successfully.\")\n",
    "    # Construct INSERT query with placeholders\n",
    "columns_str = \", \".join([f'\"{col}\"' for col in columns])\n",
    "placeholders = \", \".join([\"%s\"] * len(columns))\n",
    "insert_query = f'INSERT INTO {table_name} ({columns_str}) VALUES ({placeholders})'\n",
    "\n",
    "# Convert DataFrame to list of tuples\n",
    "data = [tuple(row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "# Execute batch insert safely\n",
    "cursor.executemany(insert_query, data)\n",
    "print(f\"Data inserted into '{table_name}' successfully.\")\n",
    "\n",
    "# Commit and close connection\n",
    "session.commit()\n",
    "cursor.close()\n",
    "session.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for fical_calender.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake Warehouse: COMPUTE_WH\n",
      "Snowflake Account: tm52713.ap-south-1\n",
      "Connection successful\n",
      "Schema 'API_SCHEMA' exists.\n",
      "Table 'fiscal_calendar' created successfully.\n",
      "Data inserted into 'fiscal_calendar' successfully.\n"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define connection parameters correctly\n",
    "connection_param = {\n",
    "    \"user\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    \"password\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    \"account\": \"tm52713.ap-south-1\",\n",
    "    \"database\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"schema\": os.getenv(\"SNOWFLAKE_SCHEMA\"),\n",
    "    \"warehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\")\n",
    "}\n",
    "\n",
    "# for testinbg \n",
    "print(f\"Snowflake Warehouse: {connection_param['warehouse']}\")\n",
    "print(f\"Snowflake Account: {connection_param['account']}\")\n",
    "\n",
    "session = snowflake.connector.connect(**connection_param)\n",
    "cursor = session.cursor()\n",
    "print(\"Connection successful\")\n",
    "\n",
    "csv_file_path = os.path.join(\"sample_data\", \"fiscal_calendar.csv\") \n",
    "df = pd.read_csv(csv_file_path)\n",
    "def get_column_type(col, df):\n",
    "    if df[col].dtype == 'int64':\n",
    "        return 'INTEGER'\n",
    "    elif df[col].dtype == 'float64':\n",
    "        return 'FLOAT'\n",
    "    else:\n",
    "        return 'STRING'\n",
    "    \n",
    "# type dynamically\n",
    "columns = df.columns.tolist()\n",
    "column_definitions = \", \".join([f'\"{col}\" {get_column_type(col, df)}' for col in columns])\n",
    "# df.head()\n",
    "# Your error \"Database 'API_SCHEMA' does not exist or not authorized.\" means that Snowflake is treating API_SCHEMA as a database instead of a schema.\n",
    "# This happens because in Snowflake, you must always specify the database first when referencing schemas and tables.\n",
    "database_name = connection_param[\"database\"] \n",
    "schema_name = connection_param[\"schema\"] \n",
    "table_name = \"fiscal_calendar\"\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM {database_name}.INFORMATION_SCHEMA.SCHEMATA \n",
    "    WHERE SCHEMA_NAME = '{schema_name.upper()}'\n",
    "\"\"\")\n",
    "schema_exists = cursor.fetchone()[0] > 0  \n",
    "\n",
    "if schema_exists:\n",
    "    print(f\"Schema '{schema_name}' exists.\")\n",
    "    cursor.execute(f\"USE SCHEMA {schema_name}\")  # Now it's safe to use\n",
    "else:\n",
    "    raise ValueError(f\"Schema '{schema_name}' does not exist in Snowflake. Please check your connection settings.\")\n",
    "\n",
    "# cursor.execute(f\"USE SCHEMA {schema_name}\")\n",
    "\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM {database_name}.INFORMATION_SCHEMA.TABLES \n",
    "    WHERE TABLE_SCHEMA = '{schema_name.upper()}'\n",
    "    AND TABLE_NAME = '{table_name.upper()}'\n",
    "\"\"\")\n",
    "table_exists = cursor.fetchone()[0] > 0\n",
    "if table_exists:\n",
    "    print(f\"Table '{table_name}' already exists in db '{schema_name}'.\")\n",
    "else:\n",
    "    create_table_query = f'CREATE TABLE {table_name} ({column_definitions})'\n",
    "    cursor.execute(create_table_query)\n",
    "    print(f\"Table '{table_name}' created successfully.\")\n",
    "    # Construct INSERT query with placeholders\n",
    "columns_str = \", \".join([f'\"{col}\"' for col in columns])\n",
    "placeholders = \", \".join([\"%s\"] * len(columns))\n",
    "insert_query = f'INSERT INTO {table_name} ({columns_str}) VALUES ({placeholders})'\n",
    "\n",
    "# Convert DataFrame to list of tuples\n",
    "data = [tuple(row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "# Execute batch insert safely\n",
    "cursor.executemany(insert_query, data)\n",
    "print(f\"Data inserted into '{table_name}' successfully.\")\n",
    "\n",
    "# Commit and close connection\n",
    "session.commit()\n",
    "cursor.close()\n",
    "session.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# orders.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake Warehouse: COMPUTE_WH\n",
      "Snowflake Account: tm52713.ap-south-1\n",
      "Connection successful\n",
      "Schema 'API_SCHEMA' exists.\n",
      "Table 'orders' created successfully.\n",
      "Data inserted into 'orders' successfully.\n"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define connection parameters correctly\n",
    "connection_param = {\n",
    "    \"user\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    \"password\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    \"account\": \"tm52713.ap-south-1\",\n",
    "    \"database\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"schema\": os.getenv(\"SNOWFLAKE_SCHEMA\"),\n",
    "    \"warehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\")\n",
    "}\n",
    "\n",
    "# for testinbg \n",
    "print(f\"Snowflake Warehouse: {connection_param['warehouse']}\")\n",
    "print(f\"Snowflake Account: {connection_param['account']}\")\n",
    "\n",
    "session = snowflake.connector.connect(**connection_param)\n",
    "cursor = session.cursor()\n",
    "print(\"Connection successful\")\n",
    "\n",
    "csv_file_path = os.path.join(\"sample_data\", \"orders.csv\") \n",
    "df = pd.read_csv(csv_file_path)\n",
    "def get_column_type(col, df):\n",
    "    if df[col].dtype == 'int64':\n",
    "        return 'INTEGER'\n",
    "    elif df[col].dtype == 'float64':\n",
    "        return 'FLOAT'\n",
    "    else:\n",
    "        return 'STRING'\n",
    "    \n",
    "# type dynamically\n",
    "columns = df.columns.tolist()\n",
    "column_definitions = \", \".join([f'\"{col}\" {get_column_type(col, df)}' for col in columns])\n",
    "# df.head()\n",
    "# Your error \"Database 'API_SCHEMA' does not exist or not authorized.\" means that Snowflake is treating API_SCHEMA as a database instead of a schema.\n",
    "# This happens because in Snowflake, you must always specify the database first when referencing schemas and tables.\n",
    "database_name = connection_param[\"database\"] \n",
    "schema_name = connection_param[\"schema\"] \n",
    "table_name = \"orders\"\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM {database_name}.INFORMATION_SCHEMA.SCHEMATA \n",
    "    WHERE SCHEMA_NAME = '{schema_name.upper()}'\n",
    "\"\"\")\n",
    "schema_exists = cursor.fetchone()[0] > 0 \n",
    "\n",
    "if schema_exists:\n",
    "    print(f\"Schema '{schema_name}' exists.\")\n",
    "    cursor.execute(f\"USE SCHEMA {schema_name}\") \n",
    "else:\n",
    "    raise ValueError(f\"Schema '{schema_name}' does not exist in Snowflake. Please check your connection settings.\")\n",
    "\n",
    "# cursor.execute(f\"USE SCHEMA {schema_name}\")\n",
    "\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM {database_name}.INFORMATION_SCHEMA.TABLES \n",
    "    WHERE TABLE_SCHEMA = '{schema_name.upper()}'\n",
    "    AND TABLE_NAME = '{table_name.upper()}'\n",
    "\"\"\")\n",
    "table_exists = cursor.fetchone()[0] > 0\n",
    "if table_exists:\n",
    "    print(f\"Table '{table_name}' already exists in db '{schema_name}'.\")\n",
    "else:\n",
    "    create_table_query = f'CREATE TABLE {table_name} ({column_definitions})'\n",
    "    cursor.execute(create_table_query)\n",
    "    print(f\"Table '{table_name}' created successfully.\")\n",
    "    # Construct INSERT query with placeholders\n",
    "columns_str = \", \".join([f'\"{col}\"' for col in columns])\n",
    "placeholders = \", \".join([\"%s\"] * len(columns))\n",
    "insert_query = f'INSERT INTO {table_name} ({columns_str}) VALUES ({placeholders})'\n",
    "\n",
    "# Convert DataFrame to list of tuples\n",
    "data = [tuple(row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "# Execute batch insert safely\n",
    "cursor.executemany(insert_query, data)\n",
    "print(f\"Data inserted into '{table_name}' successfully.\")\n",
    "\n",
    "# Commit and close connection\n",
    "session.commit()\n",
    "cursor.close()\n",
    "session.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# products.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake Warehouse: COMPUTE_WH\n",
      "Snowflake Account: tm52713.ap-south-1\n",
      "Connection successful\n",
      "Schema 'API_SCHEMA' exists.\n",
      "Table 'products' created successfully.\n",
      "Data inserted into 'products' successfully.\n"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define connection parameters correctly\n",
    "connection_param = {\n",
    "    \"user\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    \"password\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    \"account\": \"tm52713.ap-south-1\",\n",
    "    \"database\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"schema\": os.getenv(\"SNOWFLAKE_SCHEMA\"),\n",
    "    \"warehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\")\n",
    "}\n",
    "\n",
    "# for testinbg \n",
    "print(f\"Snowflake Warehouse: {connection_param['warehouse']}\")\n",
    "print(f\"Snowflake Account: {connection_param['account']}\")\n",
    "\n",
    "session = snowflake.connector.connect(**connection_param)\n",
    "cursor = session.cursor()\n",
    "print(\"Connection successful\")\n",
    "\n",
    "csv_file_path = os.path.join(\"sample_data\", \"products.csv\") \n",
    "df = pd.read_csv(csv_file_path)\n",
    "def get_column_type(col, df):\n",
    "    if df[col].dtype == 'int64':\n",
    "        return 'INTEGER'\n",
    "    elif df[col].dtype == 'float64':\n",
    "        return 'FLOAT'\n",
    "    else:\n",
    "        return 'STRING'\n",
    "    \n",
    "# type dynamically\n",
    "columns = df.columns.tolist()\n",
    "column_definitions = \", \".join([f'\"{col}\" {get_column_type(col, df)}' for col in columns])\n",
    "# df.head()\n",
    "# Your error \"Database 'API_SCHEMA' does not exist or not authorized.\" means that Snowflake is treating API_SCHEMA as a database instead of a schema.\n",
    "# This happens because in Snowflake, you must always specify the database first when referencing schemas and tables.\n",
    "database_name = connection_param[\"database\"] \n",
    "schema_name = connection_param[\"schema\"] \n",
    "table_name = \"products\"\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM {database_name}.INFORMATION_SCHEMA.SCHEMATA \n",
    "    WHERE SCHEMA_NAME = '{schema_name.upper()}'\n",
    "\"\"\")\n",
    "schema_exists = cursor.fetchone()[0] > 0 \n",
    "\n",
    "if schema_exists:\n",
    "    print(f\"Schema '{schema_name}' exists.\")\n",
    "    cursor.execute(f\"USE SCHEMA {schema_name}\")  \n",
    "else:\n",
    "    raise ValueError(f\"Schema '{schema_name}' does not exist in Snowflake. Please check your connection settings.\")\n",
    "\n",
    "# cursor.execute(f\"USE SCHEMA {schema_name}\")\n",
    "\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM {database_name}.INFORMATION_SCHEMA.TABLES \n",
    "    WHERE TABLE_SCHEMA = '{schema_name.upper()}'\n",
    "    AND TABLE_NAME = '{table_name.upper()}'\n",
    "\"\"\")\n",
    "table_exists = cursor.fetchone()[0] > 0\n",
    "if table_exists:\n",
    "    print(f\"Table '{table_name}' already exists in db '{schema_name}'.\")\n",
    "else:\n",
    "    create_table_query = f'CREATE TABLE {table_name} ({column_definitions})'\n",
    "    cursor.execute(create_table_query)\n",
    "    print(f\"Table '{table_name}' created successfully.\")\n",
    "    # Construct INSERT query with placeholders\n",
    "columns_str = \", \".join([f'\"{col}\"' for col in columns])\n",
    "placeholders = \", \".join([\"%s\"] * len(columns))\n",
    "insert_query = f'INSERT INTO {table_name} ({columns_str}) VALUES ({placeholders})'\n",
    "\n",
    "# Convert DataFrame to list of tuples\n",
    "data = [tuple(row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "# Execute batch insert safely\n",
    "cursor.executemany(insert_query, data)\n",
    "print(f\"Data inserted into '{table_name}' successfully.\")\n",
    "\n",
    "# Commit and close connection\n",
    "session.commit()\n",
    "cursor.close()\n",
    "session.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
